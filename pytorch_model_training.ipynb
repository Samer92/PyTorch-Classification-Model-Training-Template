{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_model_training.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ksDh6-S2Wcw1","colab_type":"code","outputId":"4bf5f397-1417-49b9-b915-da1f97292fa1","executionInfo":{"status":"ok","timestamp":1571373830607,"user_tz":-180,"elapsed":3115,"user":{"displayName":"classifier template","photoUrl":"","userId":"17751933696681567409"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["import nbimporter\n","import os\n","import numpy as np\n","from PIL import Image\n","import pickle as pk\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm_notebook as tqdm\n","from IPython.display import clear_output\n","import tarfile\n","\n","from evaluation_metrics import ClassifierReport\n","from pytorch_device_manager import  DeviceManager\n","from pytorch_data_transformation import NCenterCrop\n","\n","\n","from utilities import ElapsedTime\n","from lr_finder import LRFinder\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models\n","from copy import deepcopy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Importing Jupyter notebook from evaluation_metrics.ipynb\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Importing Jupyter notebook from pytorch_device_manager.ipynb\n","Importing Jupyter notebook from pytorch_data_transformation.ipynb\n","Importing Jupyter notebook from utilities.ipynb\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UKpL2c-xWcrP","colab_type":"code","colab":{}},"source":["class ModelInitializer:\n","    def __init__(self, model_name, \n","                 use_pretrained=True, \n","                 update_head={'update': True,\n","                              'init_mode': 'xavier_normal',\n","                               'val': None},\n","                 num_classes=0, \n","                 dropout = {'add_dropout': False, 'prob': None}):\n","        \n","        self.model_name = model_name\n","        self.model = None\n","        self.num_classes = num_classes\n","        self.update_head = update_head\n","        self.dropout = dropout\n","        self.use_pretrained = use_pretrained\n","    \n","    @staticmethod\n","    def update_trainability(layers: list, trainable):\n","        for layer in layers:\n","            for params in layer.parameters():\n","                params.requires_grad = trainable\n","    \n","    @staticmethod\n","    def init_layer_weight(layer, init_mode, val):\n","        \n","        if init_mode is None:\n","            return\n","          \n","        elif init_mode == 'uniform':\n","            torch.nn.init.uniform_(layer.weight)\n","            \n","        elif init_mode == 'normal':\n","            torch.nn.init.normal_(layer.weight)\n","\n","        elif init_mode == 'constant':\n","            torch.nn.init.constant_(layer.weight, val)\n","            \n","        elif init_mode == 'ones':\n","            torch.nn.init.ones_(layer.weight)\n","            \n","        elif init_mode == 'zeros':\n","            torch.nn.init.zeros_(layer.weight)\n","            \n","        elif init_mode == 'eye':\n","            torch.nn.init.eye_(layer.weight)\n","                        \n","        elif init_mode == 'dirac':\n","            torch.nn.init.dirac_(layer.weight)\n","                        \n","        elif init_mode == 'xavier_uniform':\n","            torch.nn.init.xavier_uniform_(layer.weight)\n","            \n","        elif init_mode == 'xavier_normal':\n","            torch.nn.init.xavier_normal_(layer.weight)\n","            \n","        elif init_mode == 'kaiming_uniform':\n","            torch.nn.init.kaiming_uniform_(layer.weight)\n","            \n","        elif init_mode == 'kaiming_normal':\n","            torch.nn.init.kaiming_normal_(layer.weight)\n","            \n","        elif init_mode == 'orthogonal':\n","            torch.nn.init.orthogonal_(layer.weight)\n","            \n","        elif init_mode == 'sparse':\n","            torch.nn.init.sparse_(layer.weight)\n","            \n","        if isinstance(layer, nn.BatchNorm1d) or isinstance(layer, nn.BatchNorm2d) or isinstance(layer, nn.BatchNorm3d):\n","            torch.nn.init.zeros_(layer.bias)\n","        \n","        elif layer.bias is not None:\n","            torch.nn.init.normal_(layer.bias)\n","            \n","    def creat_initialized_fc(self, num_ftrs):\n","        # Create a fc layer\n","        fc = nn.Linear(num_ftrs, self.num_classes)\n","        \n","        # Initialize the weights\n","        ModelInitializer.init_layer_weight(fc, self.update_head['init_mode'], self.update_head['val'])\n","        \n","        if self.dropout['add_dropout']:\n","            fc = nn.Sequential(nn.Dropout(self.dropout['prob']), fc)\n","        \n","        return fc\n","    \n","    def update_resnet_head(self):\n","        num_ftrs = self.model.fc.in_features\n","        \n","        self.model.fc = self.creat_initialized_fc(num_ftrs)\n","        \n","    def update_squeezenet_head(self):\n","        if self.dropout['add_dropout']:\n","            self.model.classifier[1] = nn.Sequential(nn.Dropout(self.dropout['add_dropout']),\n","                                                nn.Conv2d(512, self.num_classes, kernel_size=(1,1), stride=(1,1)))\n","          \n","            ModelInitializer.init_layer_weight(self.model.classifier[1][1], self.update_head['init_mode'], self.update_head['val'])\n","          \n","        else:\n","            self.model.classifier[1] = nn.Conv2d(512, self.num_classes, kernel_size=(1,1), stride=(1,1))\n","            ModelInitializer.init_layer_weight(self.model.classifier[1], self.update_head['init_mode'], self.update_head['val'])\n","        \n","        self.model.num_classes = self.num_classes\n","        \n","    \n","    def update_densenet_head(self):\n","        num_ftrs = self.model.classifier.in_features\n","        self.model.classifier = self.creat_initialized_fc(num_ftrs)\n","        \n","    def update_vgg_alexnet_head(self):\n","        num_ftrs = self.model.classifier[6].in_features\n","        self.model.classifier[6] = self.creat_initialized_fc(num_ftrs)\n","        \n","        \n","    def update_vgg_head(self):\n","        num_ftrs = self.model.classifier[6].in_features\n","        self.model.classifier[6] = self.creat_initialized_fc(num_ftrs)\n","        \n","    def update_inception_head(self):\n","        num_ftrs = self.model.AuxLogits.fc.in_features\n","        self.model.AuxLogits.fc = self.creat_initialized_fc(num_ftrs)\n","        \n","        num_ftrs = self.model.fc.in_features\n","        self.model.fc = self.creat_initialized_fc(num_ftrs)\n","    \n","    def get_model(self):\n","        if self.model_name == 'resnet18':\n","            self.model = models.resnet18(pretrained=self.use_pretrained)\n","            \n","        if self.model_name == 'resnet34':\n","            self.model = models.resnet34(pretrained=self.use_pretrained)\n","            \n","        if self.model_name == 'resnet50':\n","            self.model = models.resnet50(pretrained=self.use_pretrained)\n","\n","        if self.model_name == 'resnet101':\n","            self.model = models.resnet101(pretrained=self.use_pretrained)\n","            \n","        if self.model_name == 'resnet152':\n","            self.model = models.resnet152(pretrained=self.use_pretrained)\n","            \n","        if self.model_name == 'squeezenet1_0':\n","            self.model = models.squeezenet1_0(pretrained=self.use_pretrained)\n","            \n","        if self.model_name == 'squeezenet1_1':\n","            self.model = models.squeezenet1_1(pretrained=self.use_pretrained)\n","            \n","        if self.model_name == 'densenet121':\n","            self.model = models.densenet121(pretrained=self.use_pretrained)\n","            \n","        if self.model_name == 'densenet169':\n","            self.model = models.densenet169(pretrained=self.use_pretrained)\n","\n","        if self.model_name == 'densenet161':\n","            self.model = models.densenet161(pretrained=self.use_pretrained)  \n","            \n","        if self.model_name == 'densenet201':\n","            self.model = models.densenet201(pretrained=self.use_pretrained)  \n","            \n","        if self.model_name == 'alexnet':\n","            self.model = models.alexnet(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'vgg11':\n","            self.model = models.vgg11(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'vgg11_bn':\n","            self.model = models.vgg11_bn(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'vgg13':\n","            self.model = models.vgg13(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'vgg13_bn':\n","            self.model = models.vgg13_bn(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'vgg16':\n","            self.model = models.vgg16(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'vgg16_bn':\n","            self.model = models.vgg16_bn(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'vgg19':\n","            self.model = models.vgg19(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'vgg19_bn':\n","            self.model = models.vgg19_bn(pretrained=self.use_pretrained) \n","            \n","        if self.model_name == 'inception_v3':\n","            self.model = models.inception_v3(pretrained=self.use_pretrained) \n","\n","        if self.update_head['update']:\n","            if 'resnet' in self.model_name:\n","                self.update_resnet_head()\n","               \n","            if 'squeezenet' in self.model_name:\n","                self.update_squeezenet_head()\n","            \n","            if 'densenet' in self.model_name:\n","                self.update_densenet_head()\n","                \n","            if 'vgg' in self.model_name:\n","                self.update_vgg_alexnet_head()\n","                \n","            if 'alexnet' in self.model_name:\n","                self.update_vgg_alexnet_head()\n","                \n","            if 'inception' in self.model_name:\n","                self.update_inception_head()\n","            \n","        ModelInitializer.update_trainability([self.model], trainable = False)\n","        \n","        return self.model\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uu4fIOjBWciv","colab_type":"code","colab":{}},"source":["class ModelTraining:\n","  \n","    def __init__(self, model, model_name, device, loss_function = None, optimizer = None,\n","                       scheduler = None, num_epochs = None, \n","                       input_type={'train': 'single_crop','validation': 'single_crop'},\n","                       save_model_rate = 5, save_last_model = True):\n","        \n","        # Initial\n","        if model != None:\n","            self.model = model.to(device)\n","        self.model_name = model_name\n","        self.device = device\n","        self.loss_function = loss_function\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","        self.plateau_scheduler = False\n","        self.num_epochs = num_epochs\n","        self.input_type = input_type\n","        self.phases = ['train', 'validation']\n","        self.inputs = self.labels = self.outputs = self.outputs_score = self.preds = self.loss = None\n","        self.current_epoch = 0\n","        \n","        # For model saving\n","        self.save_model_rate = save_model_rate   # [epoch]\n","        self.save_last_model = save_last_model\n","        \n","        # For model steps timing\n","        self.steps_timing = dict()\n","        \n","        self.legend = {\n","                          'd_load': ('Data Loading', 'maroon'),\n","                          'd_transfer': ('Data Transfer', 'yellow'),\n","                          'zero_grads': ('Zero Gradient', 'indigo'),\n","                          'forward': ('Forward Pass', 'green'),\n","                          'prediction': ('Prediction', 'blue'),\n","                          'loss': ('Loss Computation', 'magenta'),\n","                          'backward': ('Backward Pass', 'darkcyan'),\n","                          'optimizer': ('Optimization Algorithm', 'darkslategray')\n","                      }\n","        \n","        \n","        # For model evaluation\n","        self.all_epochs_data = list()\n","        self.best_metrics = dict()\n","        self.metrics = dict()\n","        _phase = ['val', 'train']\n","        _metrics = ['acc', 'kappa', 'recall', 'fscore', 'precision', 'spec', 'loss']        \n","        for ph in _phase:\n","            for met in _metrics:\n","                self.metrics[ph + '_' + met] = list()\n","                if met == 'loss':\n","                    self.best_metrics[ph + '_' + met] = float(\"inf\")\n","                else:\n","                    self.best_metrics[ph + '_' + met] = 0\n","                   \n","    def data_loading(self, data_loader):\n","        self.inputs, self.labels = next(iter(data_loader))\n","        \n","    def data_transfer(self):\n","        self.inputs, self.labels = self.inputs.to(self.device), self.labels.to(self.device)\n","              \n","    def zero_grad(self):\n","        self.optimizer.zero_grad()\n","    \n","    def single_crop_forward(self):\n","        self.outputs = self.model(self.inputs)\n","    \n","    def multi_crops_forward(self):\n","        bs, ncrops, c, h, w = self.inputs.size()\n","        self.outputs = self.model(self.inputs.view(-1, c, h, w)).view(bs, ncrops, -1).mean(dim=1)\n","    \n","    def forward(self, input_type):\n","        \n","        if input_type == 'single_crop':\n","            self.single_crop_forward()\n","        \n","        elif input_type == 'multi_crops':\n","            self.multi_crops_forward()\n","    \n","    def get_predictions(self, dim=1):\n","        self.outputs_score = F.softmax(self.outputs, dim = dim)\n","        self.preds = self.outputs_score.argmax(dim = dim)\n","#         self.preds_prop = torch.cuda.FloatTensor(torch.tensor([self.outputs_score[i][self.preds[i]] for i in range(len(self.preds))],\n","#                                                               requires_grad=True).to(self.device))\n","    \n","    def loss_calculation(self):\n","        self.loss = self.loss_function(self.outputs, self.labels)\n","#         if isinstance(self.loss_function, nn.modules.loss._WeightedLoss):\n","#             self.loss = self.loss_function(self.outputs, self.labels)\n","          \n","#         else:\n","#             self.loss = self.loss_function(self.preds_prop, torch.cuda.FloatTensor(self.labels.float()))\n","    \n","    def backward(self):\n","        self.loss.backward()\n","        \n","    def optimizer_step(self):\n","        self.optimizer.step()\n","    \n","    def scheduler_step(self, best):\n","        if self.scheduler is not None:\n","            if self.plateau_scheduler:\n","                self.scheduler.step(self.best_metrics[best])\n","            else:\n","                self.scheduler.step()\n","    \n","    def set_model_state(self, training_phase):\n","        if training_phase:\n","            self.model.train()\n","        else:\n","            self.model.eval()\n","    \n","    def initialize_phase_data(self):\n","        # Empty lists to save the scores and predications\n","        self.y_loss, self.y_true, self.y_pred, self.y_score = [list() for _ in range(4)]\n","        \n","    def update_phase_data(self):\n","        # Store the results\n","        self.y_loss.append(self.loss.view(1))\n","        self.y_true.append(self.labels)\n","        self.y_pred.append(self.preds)\n","        self.y_score.append(self.outputs_score)\n","    \n","    def initialize_epoch_data(self):\n","        self.current_epoch += 1\n","        self.epoch_data = dict()\n","    \n","    def update_epoch_data(self, epoch, phase):\n","        self.epoch_data['current_epoch'] = epoch\n","        self.epoch_data['y_loss_' + phase] = torch.cat(self.y_loss).cpu().detach().numpy()\n","        self.epoch_data['y_true_' + phase] = torch.cat(self.y_true).cpu().detach().numpy()\n","        self.epoch_data['y_pred_' + phase] = torch.cat(self.y_pred).cpu().detach().numpy()\n","        self.epoch_data['y_score_'+ phase] = torch.cat(self.y_score).cpu().detach().numpy()\n","    \n","    def one_phase(self, phase, dataset):\n","        \n","        print('The current phase is {}'.format(phase))\n","        training_phase = phase == self.phases[0]\n","        \n","        self.set_model_state(training_phase)\n","        data_loader = dataset.get_data_loader(training_phase)\n","        \n","        self.initialize_phase_data()\n","        \n","        for self.inputs, self.labels in data_loader:\n","            self.data_transfer()\n","            self.zero_grad()\n","            \n","            with torch.set_grad_enabled(training_phase):\n","                self.forward(self.input_type[phase])\n","                self.get_predictions()\n","                self.loss_calculation()\n","            \n","            if training_phase:\n","                self.backward()\n","                self.optimizer_step()\n","                \n","            self.update_phase_data()\n","    \n","    def one_epoch(self, dataset, epoch, best):\n","        \n","        self.initialize_epoch_data()\n","        self.scheduler_step(best)\n","        \n","        for phase in self.phases:\n","            self.one_phase(phase, dataset)\n","            self.update_epoch_data(epoch, phase)\n","\n","        self.all_epochs_data.append(self.epoch_data)\n","\n","        # Clear the cell then display the result\n","        clear_output()\n","        print('Epoch {}/{}'.format(epoch+1, self.num_epochs))\n","        print('Current learning rate: {} '.format(self.optimizer.param_groups[0]['lr']))\n","        self.evaluation_metrics_calculation(dataset)\n","        self.evaluation_metrics_visualization()\n","        self.model_save(best)\n","\n","    def evaluation_metrics_calculation(self, dataset):\n","        # Calculate the loss\n","        epoch_data = self.epoch_data\n","        self.metrics['train_loss'].append(epoch_data['y_loss_train'].mean())\n","        self.metrics['val_loss'].append(epoch_data['y_loss_validation'].mean())\n","        \n","        # Calculate the evaluation metrics\n","        self.train_report = ClassifierReport(epoch_data['y_true_train'], epoch_data['y_pred_train'], \n","                                        epoch_data['y_score_train'], number_of_classes = dataset.number_of_classes,\n","                                        classes_labels = dataset.classes_names)\n","        self.metrics['train_acc'].append(self.train_report.overall_accuracy)\n","        self.metrics['train_kappa'].append(self.train_report.overall_cohen_kappa)\n","        self.metrics['train_recall'].append(self.train_report.overall_recall)\n","        self.metrics['train_fscore'].append(self.train_report.overall_f1_score)\n","        self.metrics['train_precision'].append(self.train_report.overall_precision)\n","        self.metrics['train_spec'].append(self.train_report.overall_specificity)\n","        \n","        \n","        self.val_report = ClassifierReport(epoch_data['y_true_validation'], epoch_data['y_pred_validation'], \n","                                      epoch_data['y_score_validation'], number_of_classes = dataset.number_of_classes,\n","                                      classes_labels = dataset.classes_names)\n","        self.metrics['val_acc'].append(self.val_report.overall_accuracy)\n","        self.metrics['val_kappa'].append(self.val_report.overall_cohen_kappa)\n","        self.metrics['val_recall'].append(self.val_report.overall_recall)\n","        self.metrics['val_fscore'].append(self.val_report.overall_f1_score)\n","        self.metrics['val_precision'].append(self.val_report.overall_precision)\n","        self.metrics['val_spec'].append(self.val_report.overall_specificity)\n","    \n","    def evaluation_metrics_visualization(self):\n","        \n","        def line_plot(y_train, y_val, metric):\n","            \n","            print('\\n')\n","            if metric == 'Loss':\n","                print('Training {} Min: {:0.3f} in epoch {}, Max: {:0.3f}, Current: {:0.3f}'.format(\n","                    metric, min(y_train), np.array(y_train).argmin(), max(y_train), y_train[-1]))\n","                print('Validation {} Min: {:0.3f} in epoch {}, Max: {:0.3f}, Current: {:0.3f}'.format(\n","                    metric, min(y_val), np.array(y_val).argmin(), max(y_val), y_val[-1]))\n","                \n","            else:\n","                print('Training {} Min: {:0.3f}, Max: {:0.3f} in epoch {}, Current: {:0.3f}'.format(\n","                      metric, min(y_train), max(y_train), np.array(y_train).argmax(), y_train[-1]))\n","                print('Validation {} Min: {:0.3f}, Max: {:0.3f} in epoch {}, Current: {:0.3f}'.format(\n","                      metric, min(y_val), max(y_val), np.array(y_val).argmax(), y_val[-1]))\n","            plt.figure(figsize=(9,5))\n","            plt.plot(y_train, label='Training')\n","            plt.plot(y_val, label='Validation')\n","            plt.xlabel('Epoch')\n","            plt.ylabel(metric)\n","            plt.ylim([0, max([1] + y_train + y_val)])\n","            plt.title(metric)\n","            plt.grid(True)\n","            plt.legend()\n","            plt.show()\n","            \n","            \n","        print('Training')\n","        self.train_report.show_all()\n","        \n","        print(50 * ' - ')\n","        \n","        print('Validation')\n","        self.val_report.show_all()\n","       \n","        line_plot(self.metrics['train_loss'],      self.metrics['val_loss'],      'Loss')\n","        line_plot(self.metrics['train_acc'],       self.metrics['val_acc'],       'Accuracy')\n","        line_plot(self.metrics['train_kappa'],     self.metrics['val_kappa'],     'Cohen Kappa')\n","        line_plot(self.metrics['train_fscore'],    self.metrics['val_fscore'],    'F1-Score')\n","        line_plot(self.metrics['train_precision'], self.metrics['val_precision'], 'Precision')\n","        line_plot(self.metrics['train_recall'],    self.metrics['val_recall'],    'Recall')\n","        line_plot(self.metrics['train_spec'],      self.metrics['val_spec'],      'Specificity')\n","      \n","    \n","    def model_save(self, best):\n","        def save_main_parameters(self):\n","            to_be_saved = dict()\n","            to_be_saved['epoch_data'] = self.epoch_data\n","            to_be_saved['steps_timing'] = self.steps_timing\n","            to_be_saved['train_report'] = self.train_report\n","            to_be_saved['val_report'] = self.val_report\n","            to_be_saved['metrics'] = self.metrics\n","            to_be_saved['best_metrics'] = self.best_metrics\n","            to_be_saved['model_name'] = self.model_name\n","            to_be_saved['device'] = self.device\n","            to_be_saved['loss_function'] = self.loss_function\n","            to_be_saved['current_epoch'] = self.current_epoch\n","            to_be_saved['num_epochs'] = self.num_epochs\n","            to_be_saved['input_type'] = self.input_type\n","            \n","            params = self.optimizer.param_groups\n","            lr = [params[i]['lr'] for i in reversed(range(len(params)))]\n","            to_be_saved['optimizer_lr'] = lr\n","            return to_be_saved\n","        \n","        # Update the best metric\n","        model_improved = False\n","        for key in self.best_metrics:\n","            if (key in ['train_loss', 'val_loss']) and (self.metrics[key][-1] < self.best_metrics[key]) or \\\n","               (key not in ['train_loss', 'val_loss']) and (self.metrics[key][-1] > self.best_metrics[key]):\n","                \n","                if best == key:    \n","                    model_improved = True\n","                    \n","                \n","                try:\n","                    if (self.metrics[best][-1] == self.metrics[best][-2]) and \\\n","                       (self.metrics['val_loss'][-1] < self.best_metrics['val_loss']):\n","\n","                        model_improved = True\n","\n","                except:\n","                    pass\n","                    \n","                self.best_metrics[key] = self.metrics[key][-1]\n","            \n","        # Save the model\n","        file_name = self.model_name + '.pkl'\n","        should_be_saved = False\n","        if model_improved:\n","            should_be_saved = True\n","            to_save = {\n","                           'last_model': self.model if self.save_last_model else None,\n","                           'last_params': save_main_parameters(self),\n","                           \n","                           'best_model': self.model,\n","                           'best_params': save_main_parameters(self)\n","                      }\n","        \n","        elif self.epoch_data['current_epoch'] % self.save_model_rate == 0:\n","            should_be_saved = True\n","            if os.path.exists(file_name):\n","                with open(file_name, 'rb') as f:\n","                    prev_model = pk.load(f)\n","            else:\n","                prev_model = None\n","            \n","            to_save = {\n","                           'last_model': self.model if self.save_last_model else None,\n","                           'last_params': save_main_parameters(self),\n","                           \n","                           'best_model': prev_model['best_model'] if prev_model is not None else None,\n","                           'best_params': prev_model['best_params'] if prev_model is not None else None\n","            }\n","        \n","        if should_be_saved:\n","            with open(file_name, 'wb') as f:\n","                pk.dump(to_save, f)\n","        \n","    def loop(self, dataset, best = 'val_acc', reset_epoch_cnt=True):\n","        \n","        if reset_epoch_cnt:\n","            # If we want continue training\n","            self.current_epoch = 0\n","        \n","        for epoch in range(self.num_epochs):\n","            with ElapsedTime('One epoch').cpu(with_gpu=False):\n","                self.one_epoch(dataset, epoch, best)\n","                \n","    \n","    def features_extraction_details(self, n_crops, source_layers, phase, iteration, labels):\n","        clear_output()\n","        print('Number of crops is {}'.format(n_crops))\n","        print('Number of sources {}'.format(len(source_layers)))\n","        print('Current phase is {}'.format(phase))\n","        print('Iteration {}'.format(iteration))\n","        print('labels {}'.format(len(labels)))\n","    \n"," \n","    def extract_features(self, dataset, new_ds_dir, features_layer = {\n","                                                                   'last_layer': True,\n","                                                                   'classifier': True,\n","                                                                   'softmax': True\n","                                                               }):\n","      \n","        # Get number of crops if found\n","        n_crops = 1\n","        for tr in dataset.data_transforms['train'].transforms:\n","            if isinstance(tr, NCenterCrop):\n","                n_crops = tr.n\n","                break\n","        \n","        # Get features sources\n","        layers = list()  \n","        for k in features_layer:\n","            if features_layer[k]:\n","                if k == 'softmax':\n","                    layers.append('mean_' + k)\n","                    layers.append(k + '_mean')\n","                    \n","                else:\n","                    layers.append(k)\n","                    \n","        # Generate dataset name \n","        experiment_name = lambda model_name, features, n_crops :  model_name + '_ftrs_' + features + '_crops' + str(n_crops) + '.pkl'\n","        \n","        # dataset dict\n","        datasets = {\n","            layer: {\n","                'name': experiment_name(self.model_name.split('/')[-1], layer, n_crops),\n","                'train': {'features': list(), 'labels': list()},\n","                'validation': {'features': list(), 'labels': list()}\n","            } for layer in layers\n","        }\n","        \n","        # divide model into three steps\n","        model_steps = dict()\n","        \n","        # Step 1: get last layer outputs\n","        temp = deepcopy(self.model)\n","        if isinstance(self.model, models.resnet.ResNet):\n","            temp.fc = nn.Identity()\n","            # Step 2: get fc layer outputs \n","            model_steps['classifier'] = self.model.fc\n","            \n","        elif isinstance(self.model, models.squeezenet.SqueezeNet):\n","            temp.classifier = nn.Identity()\n","            # Step 2: get fc layer outputs \n","            model_steps['classifier'] = self.model.classifier\n","            \n","        elif isinstance(self.model, models.densenet.DenseNet):\n","            temp.classifier = nn.Identity()\n","            # Step 2: get fc layer outputs \n","            model_steps['classifier'] = self.model.classifier\n","            \n","        model_steps['last_layer'] = temp\n","        \n","        \n","        \n","        # Step 3: get softmax outputs \n","        model_steps['softmax'] = F.softmax\n","\n","        for phase in self.phases:\n","            training_phase = phase == self.phases[0]\n","            \n","            # Set the model state to Evaluation\n","            self.set_model_state(False)\n","            \n","            # Get the dataset\n","            ds = dataset.get_data_loader(training_phase).dataset\n","            \n","            iteration = 0\n","            # Iterate over data\n","            for self.inputs, self.labels in ds:\n","                \n","                # Print some details\n","                if iteration % 1000 == 0: \n","                    self.features_extraction_details(n_crops, layers, phase, iteration)\n","                \n","                iteration+= 1\n","                \n","                self.inputs = self.inputs.to(self.device)\n","                                \n","                with torch.no_grad():\n","                    \n","                    # Step 1: feed model with inputs and get last layer outputs \n","                    last_layer_outputs = model_steps['last_layer'](self.inputs)\n","                    last_layer_outputs_mean = last_layer_outputs.mean(dim = 0)\n","                    \n","                    if features_layer['last_layer']:\n","                        datasets['last_layer'][phase]['features'].append(last_layer_outputs_mean.cpu().detach().numpy())\n","        \n","                    # Step 2: feed fc layer with last layer outputs \n","                    classifier_outputs = model_steps['classifier'](last_layer_outputs)\n","                    classifier_outputs_mean = classifier_outputs.mean(dim = 0)\n","                    \n","                    if features_layer['classifier']:\n","                        datasets['classifier'][phase]['features'].append(classifier_outputs_mean.cpu().detach().numpy())\n","              \n","            \n","                    # Step 3: feed softmax with classifier outputs \n","                    if features_layer['softmax']:\n","                        mean_softmax_outputs = model_steps['softmax'](classifier_outputs_mean, dim=0)\n","                        softmax_outputs_mean = model_steps['softmax'](classifier_outputs, dim = 1).mean(dim = 0)\n","                      \n","                        datasets['mean_softmax'][phase]['features'].append(mean_softmax_outputs.cpu().detach().numpy())\n","                        datasets['softmax_mean'][phase]['features'].append(softmax_outputs_mean.cpu().detach().numpy())                    \n","                    \n","                    # Add labels\n","                    for k in datasets:\n","                        datasets[k][phase]['labels'].append(np.array(self.labels))\n","                \n","                \n","        # Stack features and labels\n","        for phase in self.phases:\n","            for k in datasets:\n","                datasets[k][phase]['features'] = np.vstack(datasets[k][phase]['features'])\n","                datasets[k][phase]['labels'] = np.hstack(datasets[k][phase]['labels'])\n","                \n","        # Save datasets        \n","        for k in datasets:\n","            file_name = os.path.join(new_ds_dir, datasets[k]['name'])\n","                \n","            with open(file_name, 'wb') as f:\n","                pk.dump(datasets[k], f)    \n","    \n","    def model_memory_size(self, bits = 32):\n","        \"\"\" Calculate the model size in MB \"\"\"\n","        total_bits = 0\n","        trainable_param = 0\n","        all_trainable_param = 0\n","        \n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad:\n","                trainable_param += np.prod(np.array(param.shape))\n","                \n","            all_trainable_param += np.prod(np.array(param.shape))\n","            total_bits += np.prod(np.array(param.shape)) * bits\n","            \n","        \n","        model_memory_size = round(10**-6 * total_bits / 8)\n","        print('model size {} MB'.format(model_memory_size))\n","        print('number of all trainable parametesrs: {}'.format(all_trainable_param))\n","        print('number of current trainable parametesrs: {}'.format(trainable_param))\n","    \n","    def model_memory_utilization(self, input_type='single_crop', batch_size=64, crops=10, dim=(224, 224)):\n","        \"\"\" How much GPU memory the model uses for the selected paramters \"\"\"\n","        dvc_mng = DeviceManager()\n","       \n","        if input_type == 'single_crop':\n","            input_size = (batch_size, 3, dim[0], dim[1])\n","        elif input_type == 'multi_crops':\n","            input_size = (batch_size, crops, 3, dim[0], dim[1])\n","        \n","        self.inputs = torch.FloatTensor(np.ndarray(input_size))\n","        self.labels = torch.LongTensor(np.zeros(batch_size))\n","        \n","        with dvc_mng.get_last_gpu_usage('Data Transfer'):\n","            self.data_transfer()\n","        try:\n","            with dvc_mng.get_last_gpu_usage('Zero gradients'):\n","                 self.zero_grad()\n","        except:\n","            pass\n","          \n","        with dvc_mng.get_last_gpu_usage('Forward'):\n","            self.forward(input_type)\n","\n","        with dvc_mng.get_last_gpu_usage('Prediction'):\n","            self.get_predictions()\n","\n","        with dvc_mng.get_last_gpu_usage('Loss'):\n","            self.loss_calculation()\n","\n","        with dvc_mng.get_last_gpu_usage('Backward'):\n","            self.backward()\n","            \n","        try:\n","            with dvc_mng.get_last_gpu_usage('Optimizor'):\n","                self.optimizer_step()\n","        except:\n","          pass\n","    \n","    def initialize_steps_timing(self):\n","        self.steps_timing = {\n","            'd_load': list(),\n","            'd_transfer': list(),\n","            'zero_grads': list(),\n","            'forward': list(),\n","            'prediction': list(),\n","            'loss': list(),\n","            'backward': list(),\n","            'optimizer': list()\n","        }\n","    \n","    def for_loop_timing(self, dataset, number_iters = 50, show_time=True):\n","        self.initialize_steps_timing()\n","        data_loader = dataset.get_data_loader(True)\n","        \n","        cnt = 0\n","        for self.inputs, self.labels in data_loader:\n","            self.common_operations_timing(show_time, self.input_type['train'])\n","            \n","            cnt += 1\n","            if cnt == number_iters:\n","                break\n","     \n","    def while_loop_timing(self, dataset, number_iters = 50, show_time=True):\n","        self.initialize_steps_timing()\n","        data_loader = dataset.get_data_loader(True)\n","        \n","        cnt = 0\n","        while cnt != number_iters:\n","            with ElapsedTime('Data loading', times_list=self.steps_timing['d_load'], show_time=show_time).cpu(with_gpu=True):\n","                self.data_loading(data_loader)\n","            \n","            self.common_operations_timing(show_time, self.input_type['train'])\n","            \n","            cnt += 1\n","            \n","    def common_operations_timing(self, show_time, input_type='single_crop'):\n","        with ElapsedTime('Data transfer', times_list=self.steps_timing['d_transfer'], show_time=show_time).cpu(with_gpu=True):\n","            self.data_transfer()\n","        \n","        with ElapsedTime('Zero gradients', times_list=self.steps_timing['zero_grads'], show_time=show_time).gpu():\n","            self.zero_grad()\n","        \n","        with ElapsedTime('Forward', times_list=self.steps_timing['forward'], show_time=show_time).gpu():\n","            self.forward(input_type)\n","            \n","        with ElapsedTime('Prediction', times_list=self.steps_timing['prediction'], show_time=show_time).gpu():\n","            self.get_predictions()\n","        \n","        with ElapsedTime('Loss', times_list=self.steps_timing['loss'], show_time=show_time).gpu():\n","            self.loss_calculation()\n","        \n","        with ElapsedTime('Backward', times_list=self.steps_timing['backward'], show_time=show_time).gpu():\n","            self.backward()\n","        \n","        with ElapsedTime('Optimizer', times_list=self.steps_timing['optimizer'], show_time=show_time).gpu():\n","            self.optimizer_step()\n","        \n","        if show_time:\n","            print(20 * '-')\n","    \n","    def steps_timing_visualization(self, not_included = []):\n","        total = list()\n","        average = list()\n","        colors = list()\n","        legends = list()\n","        valid_steps= dict()\n","        plt.figure(figsize=(8,6))\n","        plt.xlabel('Iteration number')\n","        plt.ylabel('Time [Sec]')\n","        plt.grid(True)\n","\n","        for key in self.steps_timing:\n","            if key in not_included:\n","                continue\n","                \n","            if len(self.steps_timing[key]) > 0:\n","                total.append(sum(self.steps_timing[key]))\n","                average.append(sum(self.steps_timing[key]) / len(self.steps_timing[key]))\n","                colors.append(self.legend[key][1])\n","                legends.append(self.legend[key][0])\n","                valid_steps[key] = self.steps_timing[key]\n","                plt.plot(self.steps_timing[key], label=self.legend[key][0], color=self.legend[key][1])\n","        plt.legend() \n","        plt.show()\n","        \n","        plt.figure(figsize=(8,6))\n","        plt.xlabel('Steps')\n","        plt.ylabel('Total time [Sec]')\n","        plt.grid(True)\n","        y_values = np.arange(len(valid_steps))\n","        for i in range(len(total)):\n","            plt.bar(y_values[i], total[i], color = colors[i], label = legends[i])\n","        plt.xticks(y_values, valid_steps, rotation='vertical')\n","        plt.legend()\n","        plt.show()\n","        \n","        plt.figure(figsize=(8,6))\n","        plt.xlabel('Steps')\n","        plt.ylabel('Average time per batch [Sec]')\n","        plt.grid(True)\n","        y_values = np.arange(len(valid_steps))\n","        for i in range(len(average)):\n","            plt.bar(y_values[i], average[i], color = colors[i], label = legends[i])\n","        plt.xticks(y_values, valid_steps, rotation='vertical')\n","        plt.legend()\n","        plt.show()\n","        \n","        \n","    @staticmethod\n","    def get_fetures_dataset(features_dir, dataset_name):\n","        features_dir = os.path.join(features_dir, dataset_name)\n","        with open(features_dir, 'rb') as f:\n","            return pk.load(f)\n","    \n","    @staticmethod\n","    def restore_model_training(param_dict, model_):   \n","        \n","        model_training = ModelTraining(model = model_,\n","                         model_name = param_dict['model_name'],\n","                         device = param_dict['device'],\n","                         loss_function = param_dict['loss_function'],\n","                         optimizer = None,\n","                         scheduler = None,\n","                         num_epochs = param_dict['num_epochs'],\n","                         input_type = param_dict['input_type'])\n","                \n","        model_training.epoch_data = param_dict['epoch_data']\n","        model_training.steps_timing = param_dict['steps_timing']\n","        model_training.train_report = param_dict['train_report']\n","        model_training.val_report = param_dict['val_report']\n","        model_training.metrics = param_dict['metrics']\n","        model_training.best_metrics = param_dict['best_metrics']\n","        model_training.current_epoch = param_dict['current_epoch']\n","        \n","        return model_training\n","      \n","    @staticmethod\n","    def restore_last_model_training(model_name):     \n","        with open(model_name, 'rb') as f:\n","            attr = pk.load(f)\n","        last = attr['last_params']\n","        \n","        if last == None:\n","          return last\n","        \n","        return ModelTraining.restore_model_training(last, attr['last_model'])\n","    \n","    @staticmethod\n","    def restore_best_model_training(model_name):  \n","        with open(model_name, 'rb') as f:\n","            attr = pk.load(f)\n","        \n","        best = attr['best_params']\n","        \n","        if best == None:\n","          return best\n","        \n","        return ModelTraining.restore_model_training(best, attr['best_model'])\n","    \n","    \n","    @staticmethod\n","    def best_model_metrics_visualization(best_model_name):\n","        model_training = ModelTraining.restore_best_model_training(best_model_name)\n","        model_training.evaluation_metrics_visualization()\n","        \n","        \n","    @staticmethod\n","    def last_model_metrics_visualization(model_name):\n","        model_training = ModelTraining.restore_last_model_training(model_name)\n","        model_training.evaluation_metrics_visualization()\n","    \n","    @staticmethod\n","    def pth_model_save(model_tr_path, model_name):\n","        \"\"\"\n","        model_path: path of the model training file\n","        model_name: name of the .pth file\n","        \"\"\"\n","        with open(model_tr_path, 'rb') as f:\n","            attr = pk.load(f)\n","        \n","        torch.save(attr['best_model'].cpu().state_dict(), model_name)\n","    \n","    @staticmethod\n","    def compress_model_file(model_name):\n","        \"\"\"Useful for sagemaker deployment\n","           model_name: name of the .pth file\n","        \"\"\"\n","        output_filename = model_name.split('.')[0] + '.tar.gz'\n","        \n","        with tarfile.open(output_filename, \"w:gz\") as tar:\n","            tar.add(model_name, arcname=os.path.basename(model_name))\n","            \n","    def trainable_layers_names_list(self):\n","        layers = set([])\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad:\n","                layers.add(name.rstrip('.' + name.split('.')[-1]))\n","        \n","        return layers\n","            \n","    def display_misclassification(self, model_name, dataset, to_display = 15):\n","        model_training = ModelTraining.restore_best_model_training(model_name)\n","        \n","        if model_training == None:\n","            model_training = ModelTraining.restore_last_model_training(model_name)\n","\n","        y_pred = model_training.epoch_data['y_pred_validation']\n","        y_score = model_training.epoch_data['y_score_validation']\n","        y_true = model_training.epoch_data['y_true_validation']\n","        self.scores = dict()\n","        \n","        for i in range(len(y_pred)):\n","            if y_true[i] != y_pred[i]:\n","                self.scores[i] = y_score[i][y_true[i]] \n","        \n","        \n","        sorted_scores = sorted(self.scores, key=self.scores.get)\n","        d = 0\n","        for i in sorted_scores:\n","            if d >= to_display:\n","                break\n","            image, class_label = dataset.validation_dataset.imgs[i]\n","            score = {dataset.classes_names[j]: round(float(y_score[i][j]), 4) for j in range(len(y_score[i]))}\n","            img = Image.open(image)\n","            plt.figure(figsize=(10, 10))\n","            plt.imshow(img)\n","            plt.grid(False)\n","            plt.title('Actual : {} , Classes Prediction: {} \\nimage : {}'.format(dataset.classes_names[class_label], \n","                                                                           score, \n","                                                                           image.split('/')[-1]))\n","            d+= 1\n","    \n","    def find_best_learning_rate(self, dataset, use_val_loss = False, end_lr = 10, \n","                                num_iter=100, step_mode='exp'):\n","    \n","        # For more information refer to https://github.com/davidtvs/pytorch-lr-finder\n","        lr_finder = LRFinder(self.model, self.optimizer, self.loss_function, self.device)\n","    \n","        if use_val_loss:\n","            # Use validation loss as an indicator\n","            lr_finder.range_test(dataset.training_loader, val_loader=dataset.validation_loader, \n","                           end_lr=end_lr, num_iter=num_iter, step_mode=step_mode)\n","      \n","        else:\n","            # Use training loss as an indicator\n","            lr_finder.range_test(dataset.training_loader, end_lr=end_lr, num_iter=num_iter, step_mode=step_mode)\n","    \n","        # Plot the curve\n","        lr_finder.plot()\n","    \n","        # Reset the model and optimizor to their original status\n","        lr_finder.reset()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WkBjPBWQdWke","outputId":"6121b1a8-41c1-4524-dcaf-4d899250ea3b","executionInfo":{"status":"ok","timestamp":1571374034877,"user_tz":-180,"elapsed":1663,"user":{"displayName":"classifier template","photoUrl":"","userId":"17751933696681567409"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('Importing Done ...')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Importing Done ...\n"],"name":"stdout"}]}]}
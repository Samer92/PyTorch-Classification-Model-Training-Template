{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utilities.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"4zuB38YjKrLn","colab":{}},"source":["from contextlib import contextmanager\n","import torch\n","import time\n","\n","# import os\n","# code_dir = '/content/drive/My Drive/classifier_template'   # Code directory\n","# try:\n","#     os.chdir(code_dir)\n","# except Exception as e:\n","#     print(e)\n","# from pytorch_device_manager import  DeviceManager"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HjJFiXDve3ni","colab_type":"code","colab":{}},"source":["class ElapsedTime:\n","    def __init__(self, message, times_list = None, fp_digits=6, show_time = True):\n","        self.times_list = times_list\n","        self.fp_digits = fp_digits\n","        self.show_time = show_time\n","        self.message = message\n","    \n","    def __show_time(self, e):\n","        \n","        if self.show_time:\n","            if e >= 1:\n","                print('{} takes {:.0f} [m] {:.0f} [s]'.format(self.message, e // 60, e % 60))\n","            else:\n","                print('{} takes {} [s]'.format(self.message, e))\n","    \n","    def __save_time(self, e):\n","        if type(self.times_list) is list:\n","            self.times_list.append(e)\n","    \n","    @contextmanager\n","    def cpu(self, with_gpu=False):\n","        s = time.perf_counter()\n","        yield None\n","        \n","        if with_gpu:\n","            torch.cuda.synchronize()\n","        \n","        e = round(time.perf_counter() - s, self.fp_digits)\n","\n","        self.__save_time(e)\n","        self.__show_time(e)\n","    \n","    @contextmanager\n","    def gpu(self):\n","        # Define events\n","        s = torch.cuda.Event(enable_timing=True)\n","        e = torch.cuda.Event(enable_timing=True)\n","        s.record()\n","        yield None\n","\n","        torch.cuda.synchronize()\n","        e.record()\n","        torch.cuda.synchronize()\n","        \n","        e = round(s.elapsed_time(e)/1000, self.fp_digits)\n","        \n","        self.__save_time(e)\n","        self.__show_time(e)\n","        \n","    @staticmethod\n","    def consume_gpu(n, device):\n","        \"\"\" Dummy function for test purpose \"\"\"\n","        a = torch.ones((n,n), device=device)\n","        b = torch.ones((n,n), device=device)\n","        c = a * b\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqbYcOHje4wJ","colab_type":"code","colab":{}},"source":["# Some tests :)\n","# Device information\n","# dvc_mng = DeviceManager()\n","# dvc_mng.available_gpus_info()\n","# device = dvc_mng.get_gpu_device(0)\n","\n","\n","# n = 10000\n","# torch.cuda.synchronize()\n","# with ElapsedTime('CPU only').cpu(with_gpu=False):  \n","#     ElapsedTime.consume_gpu(n, device)\n","\n","# torch.cuda.synchronize()\n","# with ElapsedTime('CPU with GPU').cpu(with_gpu=True):  \n","#     ElapsedTime.consume_gpu(n, device)\n","\n","# # torch.cuda.synchronize()\n","# with ElapsedTime('With').gpu():  \n","#     ElapsedTime.consume_gpu(n, device)"],"execution_count":0,"outputs":[]}]}
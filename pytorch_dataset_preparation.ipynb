{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_dataset_preparation.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"ET6oFf2AnaZh","colab":{}},"source":["# This code to link colab to a drive account\n","# from google.colab import drive\n","# drive.mount('/content/drive/')\n","# import os\n","# code_dir = 'drive/My Drive/CG Detection/'   # Code directory\n","# try:\n","#     os.chdir(code_dir)\n","# except Exception as e:\n","#     print(e)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZdWkYE-qrOb4","colab":{}},"source":["import copy\n","import os\n","import time\n","import pandas as pd\n","import numpy as np\n","import pickle as pk\n","from tqdm import tqdm as tqdm\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from torchvision.datasets import ImageFolder\n","from torchvision import transforms\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from utilities import ElapsedTime\n","# import nbimporter\n","# from pytorch_dataset_samplers import ImbalancedDatasetSampler"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4sIjTHbhrOch","colab":{}},"source":["class PytorchDatasetPreparation:\n","    \n","    def __init__(self, dataset_dir = '', splitting_parameters = {},\n","                       loading_parameters = {}, data_transforms = {}, \n","                       show_images_dims_summary = False):\n","        \"\"\" Initialization \"\"\"\n","        \n","        # Dataset directory\n","        self.show_images_dims_summary = show_images_dims_summary\n","        \n","        if type(dataset_dir) is str:\n","            # Single dataset\n","            self.root_dir = os.path.join(os.getcwd(), dataset_dir)\n","            self.dataset_folder = NewImageFolder(self.root_dir)\n","        \n","        elif type(dataset_dir) is list:\n","            # Multiple datasets\n","            self.root_dir = [os.path.join(os.getcwd(), dr) for dr in dataset_dir]\n","            img_fld = NewImageFolder(self.root_dir[0])\n","\n","            for dr in self.root_dir[1:]:\n","                tmp_folder = ImageFolder(dr)\n","                img_fld.samples.extend(tmp_folder.samples)\n","\n","            img_fld.imgs = img_fld.samples\n","            img_fld.root = ''\n","            self.dataset_folder = img_fld\n","        \n","        self.splitting_parameters = splitting_parameters\n","        self.loading_parameters = loading_parameters\n","        self.data_transforms = data_transforms\n","        \n","        # Call details functions\n","        self.classes_details()\n","        self.samples_details = self.dataset_folder.samples_detalis()\n","        \n","        # Splitting\n","        self.train_validation_split()\n","        \n","    def classes_details(self): \n","        # Extract classes details\n","        self.number_of_classes = len(self.dataset_folder.classes)\n","        self.classes_names = self.dataset_folder.classes\n","        self.classes_idx = list(self.dataset_folder.class_to_idx.values())\n","        self.classes_names_and_idx = self.dataset_folder.class_to_idx\n","        \n","    def train_validation_split(self):\n","        \n","        # Split the samples into training and validation samples\n","        labels = [s[1] for s in self.dataset_folder.samples]\n","\n","        st = labels if self.splitting_parameters['stratified'] else None\n","            \n","        train_imgs, validation_imgs, _, _ = train_test_split(\n","            self.dataset_folder.samples, \n","            labels,\n","            test_size = self.splitting_parameters['validation_ratio'], \n","            random_state = self.splitting_parameters['splitting_random_state'],\n","            stratify=st)\n","        \n","        print('Done')\n","        # Create training dataset\n","        self.training_dataset = copy.deepcopy(self.dataset_folder)\n","        self.training_dataset.samples = train_imgs\n","        self.training_dataset.imgs = train_imgs\n","        self.training_dataset.transform = self.data_transforms['train']\n","        self.training_dataset_details = self.training_dataset.samples_detalis()\n","        \n","        # Create validation dataset\n","        self.validation_dataset = copy.deepcopy(self.dataset_folder)\n","        self.validation_dataset.samples = validation_imgs\n","        self.validation_dataset.imgs = validation_imgs\n","        self.validation_dataset.transform = self.data_transforms['validation']\n","        self.validation_dataset_details = self.validation_dataset.samples_detalis()\n","        \n","        # Create data loaders\n","        if self.loading_parameters['training_sampler_class'] is None:\n","            # No sampler is provided\n","            sampler = None\n","        else:\n","            # Extract the class and its parameters\n","            SamplerClass = self.loading_parameters['training_sampler_class']\n","            sampler_parameters = self.loading_parameters['training_sampler_parameters']\n","            \n","            # Check if it needs the data source as an argument\n","            data_source = sampler_parameters['data_source']\n","            del sampler_parameters['data_source']\n","            \n","            # Define the sampler object\n","            if data_source:\n","                sampler = SamplerClass(self.training_dataset, **sampler_parameters)\n","            else:\n","                sampler = SamplerClass(**sampler_parameters)\n","        \n","        # Define training dataset loader\n","        self.training_loader = DataLoader(self.training_dataset,\n","                                          sampler = sampler,\n","                                          batch_size = self.loading_parameters['training_batch_size'], \n","                                          shuffle = self.loading_parameters['training_shuffle'], \n","                                          num_workers = self.loading_parameters['training_num_workers'],\n","                                          pin_memory = self.loading_parameters['training_pin_memory'])\n","        \n","        # Define validation dataset loader\n","        self.validation_loader = DataLoader(self.validation_dataset, \n","                                            batch_size = self.loading_parameters['validation_batch_size'], \n","                                            shuffle = self.loading_parameters['validation_shuffle'], \n","                                            num_workers = self.loading_parameters['validation_num_workers'],\n","                                            pin_memory = self.loading_parameters['validation_pin_memory'])\n","    \n","    def show_random_images_sample(self, sample_size = 4):\n","        \"\"\" This function is to show a set of images before transformations \"\"\"\n","        if sample_size > self.samples_details['number_of_samples']:\n","            print('Sample size should be smaller than the dataset size')\n","            return\n","        \n","        rand_sample = np.random.permutation(self.samples_details['number_of_samples'])[:sample_size]\n","        plt.figure\n","        for ind in rand_sample:\n","            sample = self.dataset_folder[ind]\n","            plt.imshow(sample[0])\n","            plt.title('Image class : ' + str(sample[1]))\n","            plt.show()\n","    \n","    def show_images_after_transform(self, sample_size = 4, rand_sample = None, \n","                                    load_from = 'train'):\n","        \"\"\" This function is to show a set of images after transformations \"\"\"\n","        data_set = None\n","        \n","        if load_from not in ['train', 'validation']:\n","            print('Wrong value for load_from parameter')\n","            return\n","        \n","        if load_from == 'train':\n","            if sample_size > self.training_dataset_details['number_of_samples']:\n","                print('Sample size should be smaller than the training dataset size')\n","                return\n","          \n","            data_set = self.training_dataset\n","            number_of_samples = self.training_dataset_details['number_of_samples']\n","            \n","        if load_from == 'validation':\n","            if sample_size > self.validation_dataset_details['number_of_samples']:\n","                print('Sample size should be smaller than the validation dataset size')\n","                return\n","\n","            data_set = self.validation_dataset\n","            number_of_samples = self.validation_dataset_details['number_of_samples']\n","        \n","        if rand_sample is None:\n","            rand_sample = np.random.permutation(number_of_samples)[:sample_size]\n","        else:\n","            rand_sample = np.array(rand_sample)\n","        \n","        plt.figure()\n","        for ind in rand_sample:\n","            sample = data_set[ind]\n","            sample, label = sample[0], sample[1]\n","            sample = sample.numpy().transpose((1, 2, 0))   # Transpose since tensor is [c, h, w]\n","            mean = np.array([0.485, 0.456, 0.406])         # Mean for pretrained models\n","            std = np.array([0.229, 0.224, 0.225])          # Std for pretrained models\n","            sample = std * sample + mean\n","            sample = np.clip(sample, 0, 1)\n","            plt.imshow(sample)\n","            plt.title(self.classes_names[label])\n","            plt.show()\n","    \n","    def get_data_loader(self, training_phase):\n","        if training_phase:\n","            return self.training_loader\n","        else:\n","            return self.validation_loader\n","    \n","    def warm_up_epoch(self):\n","        with ElapsedTime('Warm up epoch').cpu(with_gpu=False):\n","            for _ in tqdm(self.training_loader, 'Training'):\n","                pass\n","              \n","            for _ in tqdm(self.validation_loader, 'Validation'):\n","                pass\n","            \n","            print('')\n","    \n","    def __repr__(self):\n","        obj_str = '* Root directory : \\n' + str(self.root_dir) + '\\n\\n'\n","        \n","        obj_str += '* Classes details : \\n'\n","        obj_str += 'Number of classes : '  + str(self.number_of_classes) + '\\n'\n","        obj_str += 'Available classes : '  + str(self.classes_names_and_idx) + '\\n\\n'\n","        \n","        if self.show_images_dims_summary:\n","            self.dims_summary = self.dataset_folder.check_images_dimensions()\n","            obj_str += '* Images dimensions details : \\n'\n","\n","            obj_str += 'Minimum width : ' + str(self.dims_summary['min_width']) + ' \\n'\n","            obj_str += 'Average width : ' + str(self.dims_summary['avr_width']) + ' \\n'\n","            obj_str += 'Maximum width : ' + str(self.dims_summary['max_width']) + ' \\n\\n'\n","\n","            obj_str += 'Minimum height : ' + str(self.dims_summary['min_height']) + ' \\n'\n","            obj_str += 'Average height : ' + str(self.dims_summary['avr_height']) + ' \\n'\n","            obj_str += 'Maximum height : ' + str(self.dims_summary['max_height']) + ' \\n'\n","\n","            obj_str += '\\n\\n'\n","        \n","        def show_samples_details(details, dataset_name):\n","            obj_str = '* ' + dataset_name + '\\n'\n","            obj_str += '** Extensions details : \\n'\n","            obj_str += 'Available extensions : '  + str(details['images_extensions']) + '\\n'\n","            obj_str += 'Number of samples per extension : \\n' + str(details['number_of_samples_per_extension']) + '\\n\\n'\n","\n","            obj_str += '** Samples details : \\n'\n","            obj_str += 'Number of samples : '  + str(details['number_of_samples']) + '\\n'\n","            obj_str += 'Number of samples per class and per extension : \\n'  + str(details['number_of_samples_per_class']) + '\\n'\n","            obj_str += 'Classes percentages : '  + str(details['classes_percentages']) + '\\n'\n","            obj_str += 'Classes weights : '  + str(details['classes_weights']) + '\\n'\n","            obj_str += '\\n\\n'\n","            return obj_str\n","        \n","        obj_str += show_samples_details(self.samples_details, 'Dataset')\n","        obj_str += show_samples_details(self.training_dataset_details, 'Training Dataset')\n","        obj_str += show_samples_details(self.validation_dataset_details, 'Validation Dataset')\n","        return obj_str"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9OGkRTzgrOc7","colab":{}},"source":["class NewImageFolder(ImageFolder):\n","    def __init__(self, root_dir):\n","        super(NewImageFolder, self).__init__(root_dir)\n","        \n","    def samples_detalis(self):\n","        # Count number of samples\n","        number_of_samples = self.samples.__len__()\n","\n","        # Extract files extensions\n","        extensions = [os.path.splitext(pth[0])[-1] for pth in self.samples]\n","\n","        # Replace any '.jpeg' by '.jpg'\n","        extensions = [ex if ex != '.jpeg' and ex != '.JPG' else '.jpg' for ex in extensions]\n","\n","        # Count number of samples for each extensions\n","        images_extensions = list(set(extensions))\n","        number_of_samples_per_extension = pd.Series(Counter(extensions))\n","\n","        # Create a dataframe for samples details\n","        columns = ['class_name', 'class_index', 'number_of_samples'] + images_extensions\n","        number_of_samples_per_class = pd.DataFrame(columns=columns)\n","\n","        # Count number of samples for each class for each extension\n","\n","        for cls_name in self.class_to_idx:\n","            # Extrac a class samples\n","            cls_ind = self.class_to_idx[cls_name]\n","\n","            cls_samples = [s[0] for s in self.samples if s[-1] == cls_ind]\n","\n","            # Count number of samples per extension per class\n","            number_of_samples_per_ext = []\n","            for ex in images_extensions:\n","                number_of_samples_per_ext.append(len(\n","                        [s for s in cls_samples if s.lower().endswith(ex)\n","                            or (s.lower().endswith('.jpeg') \n","                            and ex == '.jpg')]))\n","\n","            number_of_samples_per_class.loc[cls_ind] = \\\n","            [cls_name , cls_ind, len(cls_samples), *number_of_samples_per_ext]\n","\n","        number_of_samples_per_class.set_index('class_index', inplace=True)\n","\n","        # Calculate the classes weights and percentages\n","        num_of_smpls_cls = number_of_samples_per_class['number_of_samples'].values\n","        classes_percentage = np.array((num_of_smpls_cls/num_of_smpls_cls.sum()),\n","                                      dtype=np.float32).round(3)\n","\n","        # The higher the percentage. The lower the weight\n","        classes_weights = np.array((1/classes_percentage), dtype=np.float32).round(3)\n","\n","        return {\n","            'number_of_samples': number_of_samples,\n","            'number_of_samples_per_class': number_of_samples_per_class,\n","            'classes_weights': classes_weights,\n","            'classes_percentages': classes_percentage,\n","            'images_extensions': images_extensions,\n","            'number_of_samples_per_extension': number_of_samples_per_extension\n","            }\n","\n","\n","    def check_images_dimensions(self):\n","        \"\"\" This function extracts images dimensions. If any file is corrupted, \n","            its extenstion will be replaced by '.invalid' extension \n","        \"\"\"\n","        file_name = os.path.split(self.root)[-1] + '_imgs_dims_file.pkl'\n","        imgs_dims_file = os.path.join(os.getcwd() , file_name)\n","\n","        try:\n","            # Read the dimensions from a file if it is available\n","            with open(imgs_dims_file, 'rb') as f:\n","                imgs_dims = pk.load(f)\n","        except:\n","            print('The dimensions file is not available. A new file will be created')\n","            imgs_dims = {}\n","\n","\n","        for i in tqdm(range(self.samples.__len__()), \n","                      desc='Check the minimum and maximum image dimensions'):\n","            if self.samples[i][0] not in imgs_dims.keys():\n","                try:\n","                    # Read correctly\n","                    imgs_dims[self.samples[i][0]] = Image.open(self.samples[i][0]).size\n","                except:\n","                    # The file is corrupted (change the extension)\n","                    print('This file is corrupted : ', self.samples[i][0])\n","                    file_name, ext = os.path.splitext(self.samples[i][0])\n","                    os.rename(self.samples[i][0], file_name + '.invalid')\n","\n","            # Write the dims each 500 iterations\n","            if i % 500 == 0:\n","                # Update the dims file\n","                with open(imgs_dims_file, 'wb') as f:\n","                    pk.dump(imgs_dims, f)\n","\n","        # Update the dims file\n","        with open(imgs_dims_file, 'wb') as f:\n","            pk.dump(imgs_dims, f)\n","\n","        # Compute the dimensions average\n","        imgs_dims = list(imgs_dims.values())\n","        average_dims = np.array(np.mean(np.array(imgs_dims), axis=0), dtype=np.int16)\n","\n","        dims_summary = {}\n","\n","        # Sort according to the height (number of rows)\n","        imgs_dims.sort(key = lambda x: x[1])\n","        dims_summary['min_height'] = imgs_dims[0][1]\n","        dims_summary['max_height'] = imgs_dims[-1][1]\n","        dims_summary['avr_height'] = average_dims[1]\n","\n","        # Sort according to the width (number of columns)\n","        imgs_dims.sort(key = lambda x: x[0])\n","        dims_summary['min_width'] = imgs_dims[0][0]\n","        dims_summary['max_width'] = imgs_dims[-1][0]\n","        dims_summary['avr_width'] = average_dims[0]\n","\n","        return dims_summary\n","        \n","print('Importing Done ...')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mK8QfYuifIfO","colab_type":"code","colab":{}},"source":["# For test purpose\n","# dataset_dir = 'Dataset'   # Dataset directory\n","# root_dir = os.path.join(os.getcwd(), dataset_dir)\n","# dataset_folder = ImageFolder(root_dir)\n","# dataset_folder.check_images_dimensions()\n","# dataset_folder.samples_detalis()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxmd9wYhfIfW","colab_type":"code","colab":{}},"source":["# For test purpose\n","\n","# dataset_dir = 'Dataset'   # Dataset directory\n","# show_images_dims_summary = True\n","\n","# data_splitting_parameters = {\n","    \n","#     'validation_ratio': 0.15,\n","#     'splitting_random_state': 1,\n","# }\n","\n","# data_loading_parameters = {\n","#     'training_batch_size': 128,\n","#     'validation_batch_size': 128,\n","    \n","#     'training_shuffle': False,\n","#     'validation_shuffle': False,\n","    \n","#     'training_num_workers': 4,\n","#     'validation_num_workers': 4,\n","    \n","#     'training_sampler_class': ImbalancedDatasetSampler, # Could be None\n","#     'training_sampler_parameters': {'data_source': True, 'indices':None, 'num_samples':None},\n","#     # data_source is used to mention that the dataset should be passed as an argument to\n","#     # the sampler object\n","# }\n","\n","# # Data transformation\n","# normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","# to_tensor = transforms.ToTensor()\n","\n","# data_transforms = {\n","#     'train': transforms.Compose([\n","#         transforms.FiveCrop(224),\n","#         transforms.Lambda(lambda crops: torch.stack([normalize(to_tensor(crop)) for crop in crops]))\n","#     ]),\n","    \n","#     'validation': transforms.Compose([\n","#         transforms.FiveCrop(224),\n","#         transforms.Lambda(lambda crops: torch.stack([normalize(to_tensor(crop)) for crop in crops]))\n","#     ]),\n","# }\n","\n","# # Load the dataset\n","# dataset = PytorchDatasetPreparation(dataset_dir = dataset_dir,\n","#                                     splitting_parameters = data_splitting_parameters,\n","#                                     loading_parameters = data_loading_parameters,\n","#                                     data_transforms = data_transforms,\n","#                                     show_images_dims_summary = show_images_dims_summary)\n","\n","# dataset\n"],"execution_count":0,"outputs":[]}]}